version: "3.7"

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: namenode
    hostname: namenode
    environment:
      - CLUSTER_NAME=test-cluster
      - HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml:ro
      - ./hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml:ro
      - hadoop_namenode:/hadoop/dfs/name
    ports:
      - "50070:50070"
      - "8020:8020"
    expose:
      - "8020"
      - "50070"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.2
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:50070"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode
    hostname: datanode
    depends_on:
      namenode:
        condition: service_healthy
    environment:
      - SERVICE_PRECONDITION=namenode:8020
      - HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    volumes:
      - ./core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml:ro
      - ./hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml:ro
      - hadoop_datanode:/hadoop/dfs/data
    ports:
      - "50075:50075"
      - "50010:50010"
    expose:
      - "50010"
      - "50075"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.3
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:50075"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop2.7.4-java8
    container_name: resourcemanager
    hostname: resourcemanager
    depends_on:
      namenode:
        condition: service_healthy
      datanode:
        condition: service_healthy
    environment:
      - SERVICE_PRECONDITION=namenode:8020 datanode:50075
      - HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    volumes:
      - ./core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml:ro
      - ./yarn-site.xml:/opt/hadoop/etc/hadoop/yarn-site.xml:ro
      - ./capacity-scheduler.xml:/opt/hadoop/etc/hadoop/capacity-scheduler.xml:ro
    ports:
      - "8088:8088"
      - "8032:8032"
    expose:
      - "8030"
      - "8031"
      - "8032"
      - "8088"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.4
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop2.7.4-java8
    container_name: nodemanager
    hostname: nodemanager
    depends_on:
      resourcemanager:
        condition: service_healthy
    environment:
      - SERVICE_PRECONDITION=resourcemanager:8088
      - HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    volumes:
      - ./core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml:ro
      - ./yarn-site.xml:/opt/hadoop/etc/hadoop/yarn-site.xml:ro
    ports:
      - "8042:8042"
    expose:
      - "8041"
      - "8042"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.5
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8042/node"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  hive-metastore-postgresql:
    image: postgres:9.6-alpine
    container_name: hive-metastore-postgresql
    hostname: hive-metastore-postgresql
    environment:
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hive
      - POSTGRES_DB=metastore
    volumes:
      - hive_metastore_db:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    expose:
      - "5432"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.6
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive -d metastore"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    hostname: hive-metastore
    depends_on:
      hive-metastore-postgresql:
        condition: service_healthy
      namenode:
        condition: service_healthy
      datanode:
        condition: service_healthy
    command: ["/opt/hive/init-hive-metastore.sh"]
    environment:
      - SERVICE_PRECONDITION=namenode:8020 datanode:50075 hive-metastore-postgresql:5432
      - HIVE_OPTS=-hiveconf hive.metastore.uris=thrift://hive-metastore:9083
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    volumes:
      - ./hive-site.xml:/opt/hive/conf/hive-site.xml:ro
      - ./core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml:ro
      - ./hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml:ro
      - ./init-hive-metastore.sh:/opt/hive/init-hive-metastore.sh:ro
    ports:
      - "9083:9083"
    expose:
      - "9083"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.7
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9083"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    hostname: hive-server
    depends_on:
      hive-metastore:
        condition: service_healthy
    environment:
      - SERVICE_PRECONDITION=hive-metastore:9083
      - HIVE_OPTS=-hiveconf hive.metastore.uris=thrift://hive-metastore:9083
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    volumes:
      - ./hive-site.xml:/opt/hive/conf/hive-site.xml:ro
      - ./core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml:ro
      - ./hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml:ro
    ports:
      - "10000:10000"
      - "10002:10002"
    expose:
      - "10000"
      - "10002"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.8
        aliases:
          - hive-server.local
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "10000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  spark-master:
    image: bde2020/spark-master:2.4.5-hadoop2.7
    container_name: spark-master
    hostname: spark-master
    depends_on:
      namenode:
        condition: service_healthy
      datanode:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
      cassandra:
        condition: service_healthy
    environment:
      - SPARK_CONF_DIR=/opt/spark/conf
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - SPARK_CASSANDRA_CONNECTION_HOST=cassandra
    volumes:
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro
      - ./core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml:ro
      - ./hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml:ro
      - ./spark-cassandra-connector:/opt/spark/jars
    ports:
      - "8080:8080"
      - "7077:7077"
    expose:
      - "7077"
      - "8080"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.9
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  spark-worker:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      spark-master:
        condition: service_healthy
      cassandra:
        condition: service_healthy
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_CONF_DIR=/opt/spark/conf
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - SPARK_CASSANDRA_CONNECTION_HOST=cassandra
    volumes:
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro
      - ./core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml:ro
      - ./hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml:ro
      - ./spark-cassandra-connector:/opt/spark/jars
    ports:
      - "8081:8081"
    expose:
      - "8081"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.10
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  hue-postgres:
    image: postgres:13-alpine
    container_name: hue-postgres
    hostname: hue-postgres
    environment:
      - POSTGRES_USER=hueuser
      - POSTGRES_PASSWORD=huepassword
      - POSTGRES_DB=hue
    volumes:
      - hue_postgres_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    expose:
      - "5432"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.11
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hueuser -d hue || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  hue:
    image: gethue/hue:latest
    container_name: hue
    hostname: hue
    ports:
      - "8888:8888"
    expose:
      - "8888"
    environment:
      - HADOOP_CONF_DIR=/etc/hadoop/conf
      - HIVE_CONF_DIR=/etc/hive/conf
    volumes:
      - ./hue.ini:/usr/share/hue/desktop/conf/hue.ini:ro
      - ./core-site.xml:/etc/hadoop/conf/core-site.xml:ro
      - ./hdfs-site.xml:/etc/hadoop/conf/hdfs-site.xml:ro
      - ./yarn-site.xml:/etc/hadoop/conf/yarn-site.xml:ro
      - ./hive-site.xml:/etc/hive/conf/hive-site.xml:ro
    depends_on:
      - hive-server
      - hive-metastore
      - namenode
      - resourcemanager
      - hue-postgres
      - spark-master
      - spark-worker
      - cassandra
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.12
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8888"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  cassandra:
    image: cassandra:4.1
    container_name: cassandra
    hostname: cassandra
    environment:
      - CASSANDRA_CLUSTER_NAME=test-cluster
      - CASSANDRA_DC=dc1
      - CASSANDRA_RACK=rack1
      - CASSANDRA_ENDPOINT_SNITCH=SimpleSnitch
    volumes:
      - cassandra_data:/var/lib/cassandra
    ports:
      - "9042:9042"
      - "7000:7000"
    expose:
      - "9042"
      - "7000"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.13
    healthcheck:
      test: ["CMD", "cqlsh", "-e", "DESCRIBE KEYSPACES"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  cassandra-studio:
    image: datastax/dse-studio:6.8.0
    container_name: cassandra-studio
    hostname: cassandra-studio
    depends_on:
      cassandra:
        condition: service_healthy
    environment:
      - DS_LICENSE=accept
      - DS_STUDIO_CASSANDRA_HOST=cassandra
      - DS_STUDIO_CASSANDRA_PORT=9042
    ports:
      - "9091:9091"
    expose:
      - "9091"
    networks:
      hadoop_network:
        ipv4_address: 172.20.1.14
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 1G
      restart_policy:
        condition: on-failure
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  hadoop_network:
    driver: bridge
    name: hadoop_network
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  hadoop_namenode:
    name: hadoop_namenode
  hadoop_datanode:
    name: hadoop_datanode
  hive_metastore_db:
    name: hive_metastore_db
  hue_postgres_data:
    name: hue_postgres_data
  cassandra_data:
    name: cassandra_data
